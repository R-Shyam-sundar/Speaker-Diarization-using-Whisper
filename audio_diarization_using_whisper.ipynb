{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTO7I8tDecy4",
        "outputId": "8fe8c9ce-ace2-4317-e451-9c0d89b18e0f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_audio\n",
        "from pydub import AudioSegment\n",
        "from google.colab import drive\n",
        "\n",
        "# drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "input_path = '/content/drive/MyDrive/dataset/MPaudio1.mp4'\n",
        "output_path = '/content/extracted_audio.wav'\n",
        "\n",
        "ffmpeg_extract_audio(input_path, output_path)\n",
        "audio = AudioSegment.from_file(output_path)\n",
        "\n",
        "duration = 3 * 60 * 1000\n",
        "trimmed_audio = audio[:duration] #for first 3 minutes\n",
        "\n",
        "# trimmed_audio = audio # for final data\n",
        "trimmed_audio.export('/content/trimmed_audio.wav', format='wav')\n",
        "\n",
        "# Stereo to Mono\n",
        "stereo_audio = AudioSegment.from_file('/content/trimmed_audio.wav')\n",
        "mono_audio = stereo_audio.set_channels(1)\n",
        "mono_audio.export('/content/final_audio.wav',format='wav')\n",
        "\n",
        "output_path = '/content/final_audio.wav'"
      ],
      "metadata": {
        "id": "IxYITgmGfR9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "651ff6f6-fc6c-4718-9f39-98f5db32a410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_speakers = 2\n",
        "language = 'English'\n",
        "model_size = 'large'\n"
      ],
      "metadata": {
        "id": "buGt4moR5Mac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0_tup8RAyBy"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/openai/whisper.git > /dev/null\n",
        "!pip install -q git+https://github.com/pyannote/pyannote-audio > /dev/null\n",
        "\n",
        "import whisper\n",
        "import datetime\n",
        "\n",
        "import subprocess\n",
        "\n",
        "import torch\n",
        "import pyannote.audio\n",
        "from pyannote.audio.pipelines.speaker_verification import PretrainedSpeakerEmbedding\n",
        "embedding_model = PretrainedSpeakerEmbedding(\n",
        "    \"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "    device=torch.device(\"cuda\"))\n",
        "\n",
        "from pyannote.audio import Audio\n",
        "from pyannote.core import Segment\n",
        "\n",
        "import wave\n",
        "import contextlib\n",
        "\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/final_audio.wav'"
      ],
      "metadata": {
        "id": "DiE3hs3jnTlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(model_size)"
      ],
      "metadata": {
        "id": "Vdbad9x5CHkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transcribe(path)\n",
        "segments = result[\"segments\"]"
      ],
      "metadata": {
        "id": "z4uw8CrovIN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with contextlib.closing(wave.open(path,'r')) as f:\n",
        "  frames = f.getnframes()\n",
        "  rate = f.getframerate()\n",
        "  duration = frames / float(rate)"
      ],
      "metadata": {
        "id": "U1sZYZ_pkV1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio = Audio()\n",
        "\n",
        "def segment_embedding(segment):\n",
        "  start = segment[\"start\"]\n",
        "  end = min(duration, segment[\"end\"])\n",
        "  clip = Segment(start, end)\n",
        "  waveform, sample_rate = audio.crop(path, clip)\n",
        "  return embedding_model(waveform[None])"
      ],
      "metadata": {
        "id": "i9R5bpc3_EOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = np.zeros(shape=(len(segments), 192))\n",
        "for i, segment in enumerate(segments):\n",
        "  embeddings[i] = segment_embedding(segment)\n",
        "\n",
        "embeddings = np.nan_to_num(embeddings)"
      ],
      "metadata": {
        "id": "UPnKe_yQPWkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clustering = AgglomerativeClustering(num_speakers).fit(embeddings)\n",
        "labels = clustering.labels_\n",
        "for i in range(len(segments)):\n",
        "  segments[i][\"speaker\"] = 'SPEAKER ' + str(labels[i] + 1)"
      ],
      "metadata": {
        "id": "QHvbUf8sgUVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def time(secs):\n",
        "  return datetime.timedelta(seconds=round(secs))\n",
        "\n",
        "f = open(\"/content/transcript.txt\", \"w\")\n",
        "\n",
        "for (i, segment) in enumerate(segments):\n",
        "  if i == 0 or segments[i - 1][\"speaker\"] != segment[\"speaker\"]:\n",
        "    f.write(\"\\n\" + segment[\"speaker\"] + ' ' + str(time(segment[\"start\"])) + '\\n')\n",
        "  f.write(segment[\"text\"][1:] + ' ')\n",
        "f.close()"
      ],
      "metadata": {
        "id": "k4kitnXJLcsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/transcript.txt'\n",
        "\n",
        "with open(file_path, \"r\") as file:\n",
        "  results = file.read()\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "id": "TMiGF5K-gSPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "file_path = \"/content/final_audio.wav\"\n",
        "file_size = os.path.getsize(file_path)\n",
        "\n",
        "file_size_mb = file_size / (1024 * 1024)\n",
        "print(\"File size:\", \"{:.2f} MB\".format(file_size_mb))\n",
        "\n",
        "import shutil\n",
        "\n",
        "source_path = '/content/final_audio.wav'\n",
        "destination_path = '/content/drive/MyDrive/final_audio.wav'\n",
        "shutil.copyfile(source_path, destination_path)"
      ],
      "metadata": {
        "id": "t3fe2drWgdDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gT1BLYoiqVK-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}